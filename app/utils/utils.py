from beanie import PydanticObjectId
from datetime import datetime
from deep_translator import GoogleTranslator  # pip install deep-translator
from selenium import webdriver
from selenium.webdriver.chrome.options import Options
from bs4 import BeautifulSoup
from faker import Faker
from fastapi import APIRouter
from langchain.schema import Document
from langchain_community.document_transformers import MarkdownifyTransformer
import time, os, json, ollama, re, asyncio, httpx
from datetime import datetime
from typing import List
from app.models import Article
from langchain.schema import Document
from app.models import  CleanedArticle
from pydantic import ValidationError
from playwright.async_api import async_playwright
from bs4 import BeautifulSoup
from langchain.chat_models import ChatOpenAI
from langchain.agents import initialize_agent, Tool

def find_config(creds: str, folder=r"C:\Users\flosr\Credentials") -> dict:
    print("[LOG] √âtape 1 : Chargement du fichier de configuration...")
    config_path = os.path.join(folder, creds)
    
    if not os.path.isfile(config_path):
        print("[ERREUR] Fichier introuvable :", config_path)
        raise FileNotFoundError(f"Credential file '{creds}' not found in folder '{folder}'.")
    print("[LOG] Fichier trouv√© :", config_path)

    with open(config_path, "r", encoding="utf-8") as f:
        data = json.load(f)
        print("[LOG] Configuration charg√©e avec succ√®s.")
        return data

Prompts = find_config(creds="IA_Prompts.json")

PROMPT_TEMPLATE = Prompts.get("markdown_assistant_prompt")
print("[LOG] Template de prompt charg√© :", PROMPT_TEMPLATE[:200], "...")



async def get_article_html(url: str) -> str:
    print(f"[LOG] √âtape 2 : Extraction du HTML depuis l'URL : {url}")
    async with httpx.AsyncClient(timeout=10) as client:
        r = await client.get(url)
        html = r.text

    soup = BeautifulSoup(html, "html.parser")
    content_divs = soup.find_all("div", 
                                 class_=lambda x: x and "content" in x.lower()) + \
                   soup.find_all("div", 
                                 id=lambda x: x and "content" in x.lower())

    if not content_divs:
        content_divs = [soup.find("body")]

    allowed_tags = ["p", "h1", "h2", "h3", "h4", "h5", "li", "strong", "em"]
    cleaned_html = ""
    for div in content_divs:
        for tag in div.find_all(allowed_tags):
            cleaned_html += str(tag)

    return cleaned_html


async def html_to_markdown(html: str, batch_size: int = 1000) -> str:
    print("[LOG] √âtape 3 : Conversion du HTML en Markdown...")
    batches = []
    start = 0
    while start < len(html):
        if start + batch_size >= len(html):
            batches.append(html[start:])
            break
        end = html.rfind('.', start, start + batch_size)
        if end == -1:
            end = start + batch_size
        else:
            end += 1
        batches.append(html[start:end])
        start = end

    print(f"[LOG] {len(batches)} batchs cr√©√©s pour conversion Markdown.")
    md_transformer = MarkdownifyTransformer()
    final_md = ""
    for i, batch_html in enumerate(batches):
        print(f"[LOG] Conversion batch {i+1}/{len(batches)}...")
        doc = Document(page_content=batch_html)
        converted_docs = md_transformer.transform_documents([doc])
        final_md += converted_docs[0].page_content + "\n\n"

    print("[LOG] Conversion Markdown termin√©e. Taille finale :", len(final_md))
    return final_md


async def clean_markdown_with_llm(markdown_text: str, link: str) -> CleanedArticle:
    """
    Envoie le Markdown au LLM pour le nettoyer et extraire les m√©tadonn√©es.
    Retourne un objet CleanedArticle avec le texte final nettoy√©.
    """
    print("[LOG] √âtape 4a : Envoi du Markdown au mod√®le LLM...")
    prompt = PROMPT_TEMPLATE.format(markdown=markdown_text, link=link)

    try:
        response = ollama.chat(
            model="gemma3:latest",
            messages=[
                {"role": "system", "content": "You are an assistant that cleans markdown."},
                {"role": "user", "content": prompt}
            ],
            stream=False
        )
        print(f"[LOG] R√©ponse brute re√ßue depuis Ollama:\n{response}\nResponse Data Type: {type(response)}")
    except Exception as e:
        raise RuntimeError(f"Ollama call failed: {e}")

    # ‚úÖ Extraction du texte JSON depuis ChatResponse
    if hasattr(response, "message") and hasattr(response.message, "content"):
        content = response.message.content
    else:
        raise ValueError(f"[ERROR] Unexpected Ollama response type: {type(response)}")

    if not content:
        raise ValueError("Ollama response invalid or empty")

    # Nettoyage des backticks Markdown
    print("[LOG] Nettoyage des backticks Markdown autour du JSON...")
    if content.startswith("```json"):
        content = content[len("```json"):].strip()
    if content.endswith("```"):
        content = content[:-3].strip()

    # Conversion en dict et validation Pydantic
    print("[LOG] Tentative de parsing JSON de la r√©ponse...")
    try:
        data_dict = json.loads(content) if not isinstance(content, dict) else content
        cleaned = CleanedArticle(**data_dict)
        print("[LOG] Validation Pydantic r√©ussie ‚úÖ")
    except json.JSONDecodeError:
        print("[ERROR] R√©ponse non-JSON apr√®s nettoyage :\n", content[:300])
        raise ValueError("Ollama did not return valid JSON.")
    except ValidationError as ve:
        print("[ERROR] Validation Pydantic √©chou√©e :\n", ve)
        raise ve

    # üîπ Nettoyage final du texte pour qu'il soit plus naturel
    text = cleaned.text_clean
    text = re.sub(r'\[([^\]]+)\]\([^)]+\)', r'\1', text)     # supprime les liens Markdown
    text = re.sub(r'^\s*-\s+', '', text, flags=re.MULTILINE) # supprime les tirets isol√©s
    text = re.sub(r'https?://\S+', '', text)                 # supprime URLs seules
    text = re.sub(r'\n{3,}', '\n\n', text)                  # r√©duit les sauts de ligne multiples
    cleaned.text_clean = text.strip()

    print("[LOG] Nettoyage final du texte termin√© ‚úÖ")
    return cleaned


async def create_article_in_db(cleaned: CleanedArticle) -> Article:
    """
    Cr√©e un Article Beanie √† partir d'un CleanedArticle et l'ins√®re dans la DB.
    Applique un nettoyage regex pour rendre le texte plus naturel, √©vite les doublons,
    et traduit le texte nettoy√© en espagnol.
    """
    print("[LOG] √âtape 4b : Nettoyage final du texte avant insertion...")

    text = cleaned.text_clean

    print("[LOG] V√©rification des doublons dans la base de donn√©es...")

    # üîç V√©rifie si un article avec exactement le m√™me texte existe d√©j√†
    existing = await Article.find_one(Article.cleaned_text == text)
    if existing:
        print(f"[LOG] Doublon d√©tect√© pour l'article '{cleaned.name}' (ID: {existing.id}), insertion annul√©e.")
        return existing  # retourne l'article existant au lieu de cr√©er un doublon

    print("[LOG] Traduction du texte nettoy√© en espagnol...")

    # Traduction via GoogleTranslator
    translated_text = GoogleTranslator(source='auto', target='es').translate(text)

    print("[LOG] Texte nettoy√©, traduit, et aucun doublon trouv√© ‚úÖ")

    article = Article(
        name=cleaned.name,
        description=cleaned.description,
        link=cleaned.link,
        date_added=datetime.utcnow(),
        processed=False,
        cleaned_text=text,
        translation=translated_text
    )

    await article.insert()
    print("[LOG] Article ins√©r√© avec succ√®s dans la collection Beanie üéâ")
    return article

# Agent global, cr√©√© une seule fois
MARKETING_AGENT = None

def get_marketing_agent():
    global MARKETING_AGENT
    if MARKETING_AGENT is not None:
        return MARKETING_AGENT

    print("[LOG] Cr√©ation de l'agent marketing sp√©cialis√© pour pierres et m√©taux pr√©cieux en Colombie...")

    llm = ChatOpenAI(model_name="gpt-4", temperature=0.7)

    # D√©finition d'un outil qui prend le texte traduit et renvoie des posts courts
    def create_social_posts(text: str, link: str) -> str:
        prompt = f"""
        Tu es un expert en marketing pour pierres pr√©cieuses et m√©taux pr√©cieux en Colombie. 
        Prends ce texte traduit en espagnol et g√©n√®re 3 √† 5 textes courts percutants, informatifs et √©ducatifs,
        adapt√©s pour des posts sur les r√©seaux sociaux colombiens. 
        Ajoute le lien de l'article original √† la fin de chaque texte.
        
        Texte √† transformer : 
        {text}

        Format attendu : 
        - Texte 1
        - Texte 2
        - Texte 3
        ...
        """
        # On peut utiliser Ollama ou tout autre LLM d√©j√† int√©gr√©
        response = ollama.chat(
            model="gemma3:latest",
            messages=[{"role": "user", "content": prompt}],
            stream=False
        )
        if hasattr(response, "message") and hasattr(response.message, "content"):
            return response.message.content.strip()
        else:
            return response.strip()

    tool = Tool(
        name="SocialMediaPostsCreator",
        func=create_social_posts,
        description="Transforme un texte en plusieurs posts courts adapt√©s aux r√©seaux sociaux colombiens"
    )

    MARKETING_AGENT = initialize_agent(
        tools=[tool],
        llm=llm,
        agent="zero-shot-react-description",
        verbose=True
    )
    return MARKETING_AGENT
