from fastapi import APIRouter, Request, Query, HTTPException
from datetime import datetime
from app.models import Article, SocialPost
from typing import List, Dict, Any
import logging
from app.agents import RAGAgent
from beanie import PydanticObjectId
from fastapi import APIRouter, Request, HTTPException
from app.models import Article
import numpy as np
from sentence_transformers import SentenceTransformer  # ou ton mod√®le d'embeddings

embed_model = SentenceTransformer("all-MiniLM-L6-v2")  # exemple de mod√®le
logger = logging.getLogger("social_posts")
router = APIRouter()

@router.post("/vectorize_articles")
async def vectorize_all_articles(request: Request):
    """
    R√©cup√®re tous les articles de MongoDB et les ajoute dans l'index FAISS.
    Ignore ceux d√©j√† pr√©sents. Renvoie toujours une r√©ponse m√™me en cas d'erreur.
    """
    try:
        faiss_index = request.app.state.faiss_index
        article_ids = request.app.state.article_ids  # set des IDs d√©j√† index√©s

        # R√©cup√©rer tous les articles
        articles = await Article.find_all().to_list()
        logging.info(f"Found {len(articles)} articles in MongoDB")

        new_articles = []
        vectors_to_add = []
        ids_to_add = []

        for art in articles:
            str_id = str(art.id)
            if str_id not in article_ids:
                vector = np.array(art.embedding if hasattr(art, "embedding") else [0.0]*128, dtype='float32')
                vectors_to_add.append(vector)
                ids_to_add.append(str_id)
                new_articles.append(art)

        if vectors_to_add:
            faiss_index.add(np.array(vectors_to_add, dtype='float32'))
            article_ids.update(ids_to_add)
            logging.info(f"Added {len(new_articles)} new articles to FAISS index")
        else:
            logging.info("No new articles to add to FAISS index")

        return {"added": len(new_articles), "total_in_index": len(article_ids), "status": "success"}

    except Exception as e:
        logging.exception("Error vectorizing articles")
        # On renvoie l‚Äôerreur dans le JSON au lieu de lever une exception
        return {"added": 0, "total_in_index": len(request.app.state.article_ids), "status": "error", "detail": str(e)}

@router.post("/generate_social_posts/")
async def generate_social_posts(
    request: Request,
    count: int = Query(default=1, ge=1, le=10, description="Nombre de posts √† g√©n√©rer par article (1‚Äì10)")
):
    """
    G√©n√®re des posts sociaux pour les articles non trait√©s (processed=False).
    Utilise la traduction espagnole de chaque article.
    Marque processed=True uniquement si tous les posts sont g√©n√©r√©s correctement.
    """

    # V√©rification basique du contexte applicatif
    if not hasattr(request.app.state, "marketing_agent"):
        logger.error("üö´ Aucun agent de marketing d√©tect√© dans l'application FastAPI.")
        raise HTTPException(
            status_code=500,
            detail="Agent de marketing non initialis√© dans l'application. V√©rifiez request.app.state.marketing_agent."
        )

    marketing_agent = request.app.state.marketing_agent
    logger.info("üîé D√©marrage g√©n√©ration des posts sociaux...")
    logger.info(f"Param√®tres re√ßus : count={count}")

    try:
        unprocessed_articles = await Article.find(Article.processed == False).to_list()
    except Exception as e:
        logger.exception("üí• Erreur lors de la r√©cup√©ration des articles non trait√©s.")
        raise HTTPException(
            status_code=500,
            detail=f"Erreur lors de la lecture de la base de donn√©es : {e}"
        )

    if not unprocessed_articles:
        logger.warning("‚ö†Ô∏è Aucun article non trait√© trouv√© dans la base.")
        return {
            "success": False,
            "message": "Aucun article non trait√© trouv√©.",
            "hint": "Ajoutez ou r√©initialisez des articles avec processed=False pour les traiter."
        }

    total_articles = len(unprocessed_articles)
    logger.info(f"üìö {total_articles} article(s) √† traiter.")

    results = []
    errors = []

    for i, article in enumerate(unprocessed_articles, start=1):
        logger.info(f"\n‚Äî‚Äî‚Äî [{i}/{total_articles}] Traitement de : {article.name} ‚Äî‚Äî‚Äì")
        success = False

        try:
            # V√©rification des champs essentiels
            if not article.translation:
                msg = f"Aucune traduction espagnole trouv√©e pour l'article ({article.link})."
                logger.warning(f"üö´ {msg}")
                errors.append({
                    "article_id": str(article.id),
                    "error": msg,
                    "suggestion": "Assurez-vous que la cl√© 'translation' contient du texte espagnol."
                })
                continue

            if not isinstance(article.translation, str) or len(article.translation.strip()) < 30:
                msg = f"Contenu traduit vide ou trop court pour l'article ({article.link})."
                logger.warning(f"üö´ {msg}")
                errors.append({
                    "article_id": str(article.id),
                    "error": msg,
                    "suggestion": "V√©rifiez que la traduction de l'article est bien compl√®te."
                })
                continue

            # G√©n√©ration via agent
            logger.info(f"ü§ñ G√©n√©ration des posts via Ollama pour {article.link} ...")
            try:
                posts = await marketing_agent.generate_for_article(article.translation, article.link)
            except Exception as e:
                raise RuntimeError(f"Erreur lors de la g√©n√©ration par l'agent : {e}")

            if not posts or not isinstance(posts, list):
                raise ValueError(f"Aucun post valide g√©n√©r√© pour {article.link}.")

            posts = posts[:count]
            formatted_posts = []

            for post in posts:
                # Validation structurelle de chaque post
                if not isinstance(post, dict):
                    raise ValueError(f"Structure inattendue pour un post : {post}")
                if not all(k in post for k in ("title", "text", "tags")):
                    raise ValueError(f"Post mal form√© : {post}")

                formatted_posts.append({
                    "title": post.get("title", "Sin t√≠tulo"),
                    "text": post.get("text", "").strip(),
                    "tags": post.get("tags", [])
                })

            # V√©rification du r√©sultat final
            if not formatted_posts:
                raise ValueError(f"Aucun post utilisable g√©n√©r√© pour {article.link}.")

            # Mise √† jour DB
            article.articles = formatted_posts
            article.processed = True
            article.date_added = datetime.now()
            await article.save()
            success = True

            results.append({
                "article_id": str(article.id),
                "posts_generated": len(formatted_posts),
                "link": article.link,
                "status": "success"
            })

            logger.info(f"‚úÖ {len(formatted_posts)} posts g√©n√©r√©s et sauvegard√©s pour {article.name}")

        except Exception as e:
            logger.exception(f"üí• Erreur avec {article.link} ‚Üí {e}")
            errors.append({
                "article_id": str(article.id),
                "error": str(e),
                "suggestion": "Consultez les logs du serveur pour plus de d√©tails sur l'exception."
            })

        if not success:
            logger.info(f"‚ö†Ô∏è Article {article.name} non trait√© compl√®tement, processed reste False.")

    logger.info(f"üèÅ Termin√© : {len(results)} articles mis √† jour, {len(errors)} erreurs d√©tect√©es.")

    # R√©ponse enrichie et explicite
    return {
        "success": True if results else False,
        "message": f"Traitement termin√© : {len(results)} article(s) mis √† jour, {len(errors)} erreur(s).",
        "summary": {
            "articles_traites": len(results),
            "articles_en_erreur": len(errors),
            "total_initial": total_articles
        },
        "details_succes": results,
        "details_erreurs": errors,
        "suggestions": [
            "V√©rifiez que chaque article contient une cl√© 'translation' non vide.",
            "Assurez-vous que l'agent marketing (Ollama / LLM) est bien initialis√© et fonctionnel.",
            "Consultez les logs pour identifier les articles ignor√©s ou les erreurs de g√©n√©ration."
        ]
    }

@router.post("/ask")
async def ask_knowledge(request: Request, question: str):
    """
    Pose une question √† la base de connaissances vectorielle FAISS.
    Retourne les articles les plus proches et une r√©ponse g√©n√©r√©e.
    """
    try:
        logging.info("[/ask] Received question: %s", question)

        # Acc√®s aux ressources du serveur
        faiss_index = request.app.state.faiss_index
        rag_agent = request.app.state.rag_agent
        article_ids = list(request.app.state.article_ids)  # IDs d√©j√† dans FAISS

        if not article_ids:
            logging.warning("[/ask] No articles in FAISS yet.")
            return {"question": question, "answer": "No articles indexed yet.", "articles": []}

        # Cr√©e le vecteur de la question via l'agent RAG
        q_vector = np.array([rag_agent.markdown_agent.embed_text(question)], dtype='float32')

        # Recherche des k voisins les plus proches
        D, I = faiss_index.search(q_vector, rag_agent.top_k)
        logging.info("[/ask] FAISS returned %d nearest neighbors", len(I[0]))

        # R√©cup√©rer les IDs correspondants
        closest_ids = [article_ids[i] for i in I[0] if i < len(article_ids)]
        logging.info("[/ask] Closest article IDs: %s", closest_ids)

        # Obtenir les contenus via l'agent RAG
        result = await rag_agent.answer_question_by_ids(question, closest_ids)
        logging.info("[/ask] Returning answer to client")

        return result

    except Exception as e:
        logging.error("[/ask] Error during RAG query: %s", e)
        raise HTTPException(status_code=500, detail=f"Error in RAG query: {e}")


